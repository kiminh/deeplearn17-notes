* via its representations, architecture, loss function, and data
  transformations. Domain-appropriate biases constrain the learning problem and
  thereby compensate for data limitations. 
* A classic form of bias for vision tasks--used even before the invention of
  back propagation--is the convolutional architecture, exploiting the
  homogeneity of image statistics and the relevance of local spatial structure.
  Many generic tricks of the trade in deep learning can be cast in this
  manner--as suitable forms of domain bias. Beyond these generic tricks, I will
  work through illustrations of domains in which prior knowledge can be
  leveraged to creatively construct models. My own particular research interest
  involves 
* cognitively-informed machine learning, where an understanding of the
  mechanisms of human perception, cognition, and reasoning can serve as a
  powerful constraint on models that are intended to predict human preferences
  and behavior.

#Syllabus

* The scaling problem
* Bias-variance dilemma
* Imposing domain-appropriate bias
  - via loss functions
  - via representations and representational constraints
  - via data augmentation
  - via architecture design
* Case studies of model crafting: memory in humans and recurrent networks 
